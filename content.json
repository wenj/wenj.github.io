{"pages":[],"posts":[{"title":"Covariance Pooling for Facial Expression Recognition","text":"Link：arXiv:1805.04855 这又是一篇尝试将二阶统计量用于神经网络的paper，应用场景是表情识别。在文中，作者给出了如何使用covariance pooling做图像的表情识别和视频的表情识别。 表情识别更依赖于面部关键点的扭曲程度而不是是否存在某个关键点，因此作者认为二阶统计量相比于一阶统计量更容易捕捉到面部特征的扭曲程度，更适用于表情的识别。除此之外，covariance pooling还可以捕捉特征在各个帧之间的变化，因此可以被用在视频的表情识别中。 相较于之前使用协方差矩阵的工作，这篇文章在协方差矩阵的基础上又使用了降维层和non-linear rectification层。这一部分使用了后面提到的manifold network，它主要有两个作用：(1)由于协方差矩阵flatten后直接接全连接层过大，这部分可以起到降维的作用；(2)可以保留原矩阵中的几何信息。我猜测covariance pooling中的pooling是指降维这一部分。但是有一点有待进一步思考：Pooling最主要的作用是不变形还是降维，covariance pooling中是否有能体现不变形的部分？ 模型对于图像的表情识别，分成以下几步： 由于图像中存在很多不相关信息，首先进行脸部识别，然后根据关键点将人脸摆好。 接下来将人脸通过CNN输出特征。 使用CNN得到的特征做covariance pooling，并且把covariance matrix输入到后面接的manifold network中学习深度二阶统计量。 视频中的表情识别和图像的表情识别类似： 在视频中抽取出一些帧，进行脸部识别。 将各帧中的人脸串接起来输入到3D卷积中。 将3D CNN得到的特征做covariance pooling，并把covariance matrix输入到manifold network中。注意这一步和图像不同，这里的协方差矩阵求的是各帧的特征之间的协方差，也即时间轴上的协方差矩阵。 因此可以看到，核心就是covariance pooling和manifold network部分。 Covariance Pooling文中对于covariance pooling的描述如下： 给定一组特征 \\(f_1, f_2, …, f_n\\in \\mathbb{R}^d\\)是一组特征，他们的covariance matrix为$$\\mathbf{C}=\\frac{1}{n-1}\\sum_{i=1}^n(\\mathbf{f_i}-\\mathbf{\\bar f})(\\mathbf{f_i}-\\mathbf{\\bar f})^T$$其中，\\(\\mathbf{\\bar f}=\\frac{1}{n}\\sum_{i=1}^n\\mathbf{f_i}\\)。 对于图像中的表情识别，我们这样定义\\(f_1, f_2, …, f_n\\)：令\\(\\mathbf(X)\\in \\mathbb{R}^{w\\times h \\times d}\\)，其中\\(w,h,d\\)分别是卷积层输出的width，height和channel数。将\\(\\mathbf{X}\\) flatten成一个\\(n\\times d\\)的矩阵命名为\\(\\mathbf{X’}\\)，那么\\(f_1, f_2, …, f_n\\)就是\\(\\mathbf{X’}\\)的各列。 其实简单来看，就是将卷积层的输出中每个channel flatten成一个向量，对d个向量求协方差矩阵。 对于视频中的表情识别，用来做协方差矩阵的不再是各个channel的向量，而是从不同帧中提取出来的特征向量。细节还没有仔细研究。 SPD Manifold Network (SPDNet) Layers这部分内容来自《A Riemannian Network for SPD Matrix Learning》（arXiv:1608.04233）。SPDNet将对称正定矩阵作为输入学习出新的特征。 考虑上一部分定义的协方差矩阵\\(\\mathbf{C}\\)可能是一个对称半正定矩阵，为了符合SPDNet的输入要求，将其变成以下对称正定矩阵$$\\mathbf{C^+}=\\mathbf{C}+\\lambda trace(\\mathbf{C})\\mathbf{I}$$其中，\\(\\lambda\\)是正则化参数，\\(\\mathbf{I}\\)是单位矩阵。 SPDNet中主要有三层： Bilinear Mapping Layer (BiMap)：考虑到协方差矩阵flatten后直接接全连接层的话，全连接层输入过多，因此可以用这一层来进行降维。另一方面，这一层可以保留原矩阵的几何信息。设\\(\\mathbf{X_{k-1}}\\)是该层的输入，\\(\\mathbf{W_k}\\in \\mathbb{R}_*^{d_k \\times d_{k-1}}\\)是权重矩阵，那么输出\\(\\mathbf{X_{k}}\\in \\mathbb{R}^{d_k \\times d_k}\\)定义为$$\\mathbf{X_k}=f_b^k(\\mathbf{X_{k-1};\\mathbf{W_k}})=\\mathbf{W_k}\\mathbf{X_{k-1}}\\mathbf{W_k}^T$$ Eigenvalue Rectification (ReEig)：这一层有点类似于ReLU，可以引入非线性。设输入为\\(\\mathbf{X_{k-1}}\\)，对输入做特征值分解得到\\(\\mathbf{X_{k-1}}=\\mathbf{U_{k-1}}\\Sigma_{k-1}\\mathbf{U_{k-1}}^T\\)，那么输出\\(\\mathbf{X_{k}}\\)定义为$$\\mathbf{X_k}=f_r^k(\\mathbf{X_{k-1}})=\\mathbf{U_{k-1}}max(\\epsilon \\mathbf{I}, \\sigma_{k-1})\\mathbf{U_{k-1}}^T$$其中，max操作是逐元素取max。 Log Eigenvalue Layer (LogEig)：按照文中的说法，这一部分的作用是“给黎曼流形中的元素赋予李群结构，使得矩阵被flatten后可以使用标准的欧式运算”。这个原理超出了我的知识范围，因此目前还没有理解。好在理论难但是做法简单。设输入为\\(\\mathbf{X_{k-1}}\\)，对输入做特征值分解得到\\(\\mathbf{X_{k-1}}=\\mathbf{U_{k-1}}\\Sigma_{k-1}\\mathbf{U_{k-1}}^T\\)，那么输出\\(\\mathbf{X_{k}}\\)定义为$$\\mathbf{X_k}=f_l^k(\\mathbf{X_{k-1}})=\\mathbf{U_{k-1}}log(\\Sigma_{k-1})\\mathbf{U_{k-1}}^T$$ 把BiMap和ReEig两层用BiRe表示，那么SPDNet结构如下： 实验文章中主要用了Static Facial Expressions in the Wild (SFEW) 2.0 dataset和Real-world Affective Faces (RAF) dataset连个数据集，前者用于图像表情识别，后者用于视频表情识别。 实验中比较了使用不同的baseline训练或finetune的结果和使用covariance pooling得到的结果，使用covariance pooling可以提升三四个点。实验中还比较了covariance pooling+SPDNet中一些参数的影响，比如SPDNet后使用多少个全连接层以及SPDNet中BiRe层的个数等等，实验结果详见paper。 总结看了几篇关于如何在网络中使用二阶统计量后发现，貌似大多数paper到求covariance matrix那里都是一致的，重点在于得到covariance matrix后要怎么处理。针对这篇文章来说，就是使用SPDNet来处理covariance matrix。 对于这篇paper，还有一些细节没有搞清楚： Covariance pooling的pooling是怎么体现的。按照模型部分的描述，covariance pooling貌似只求了一个covariance matrix。 SPDNet的理论，这个超出了我的数学知识，不太能读懂。 关于视频中的表情识别文中描述的比较简略，细节不清楚。","link":"/2018/06/27/acharya18-covariance-pooling/"}],"tags":[],"categories":[]}